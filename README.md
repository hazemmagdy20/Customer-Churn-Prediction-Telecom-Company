# Customer-Churn-Prediction-Telecom-Company
This project aims to predict whether a customer will leave the company (Churn) or not, allowing the business to take proactive retention actions.

## ğŸ“Œ Project Overview
- Customer churn is one of the biggest challenges for telecom companies.

- This project aims to predict whether a customer will leave the company (Churn) or not, allowing the business to take proactive retention actions.

## ğŸ¯ Goal

- Predict customer churn using machine learning.

  ```python
  Churn = Yes â†’ Customer will leave
  Churn = No â†’ Customer will stay

- Each column in the dataset represents a potential reason why a customer might leave or stay.


## ğŸ¢ Business Context

- Define Company, Problem, Target.
  ```python
   Company: Telecom Company
   Problem Type: Binary Classification
   Target Variable: Churn

- Reducing churn directly improves:
  ```python
  Revenue retention
  Customer lifetime value
  Marketing efficiency

## ğŸ“‚ Dataset Information

- Rows: 7,043 customers
- Columns: 21 features
- Target: Churn (Yes / No)

## ğŸ§¾ Dataset Columns Explanation  

## 1ï¸âƒ£ CustomerID
- Meaning: Unique customer identifier
- Purpose: Tracking only
- ML Usage: âŒ Removed (no predictive value)

## 2ï¸âƒ£ Gender (Male / Female)
- Type: Demographic feature
- Why included: Behavioral analysis
- Impact: Usually weak, but retained

## 3ï¸âƒ£ SeniorCitizen (0 / 1)
- Binary numerical feature
- Older customers may:
- Prefer stability
- Or use fewer services

## 4ï¸âƒ£ Partner
- Indicates if customer has a partner
- Customers with partners tend to be more stable

## 5ï¸âƒ£ Dependents
- Indicates children/dependents
- Family responsibility can reduce churn

## 6ï¸âƒ£ Tenure â­
- Months with the company
- One of the strongest predictors
- Low tenure â†’ High churn
- High tenure â†’ Loyalty

## 7ï¸âƒ£ PhoneService
- Whether customer has phone service
- Fewer services â†’ Higher churn risk

## 8ï¸âƒ£ MultipleLines
- Yes / No / No phone service
- Reflects service usage level

## 9ï¸âƒ£ InternetService
- DSL / Fiber optic / No internet
- Fiber optic users show higher churn

## ğŸ”Ÿ OnlineSecurity
- Add-on service
- More services â†’ stronger attachment

## 1ï¸âƒ£1ï¸âƒ£ OnlineBackup
- Backup service
- Improves customer stickiness
  
## 1ï¸âƒ£2ï¸âƒ£ DeviceProtection
- Device insurance
- Paying more â†’ less likely to churn

## 1ï¸âƒ£3ï¸âƒ£ TechSupport â­
- One of the most important features
- No tech support â†’ high churn

## 1ï¸âƒ£4ï¸âƒ£ StreamingTV
- Lifestyle / usage intensity feature

## 1ï¸âƒ£5ï¸âƒ£ StreamingMovies
- Similar to StreamingTV
- Weak alone, useful combined

## 1ï¸âƒ£6ï¸âƒ£ Contract â­â­â­
- Month-to-month âŒ
- One year
- Two year âœ…
- Top churn driver

## 1ï¸âƒ£7ï¸âƒ£ PaperlessBilling
- Behavioral feature
- Digital users churn slightly more

## 1ï¸âƒ£8ï¸âƒ£ PaymentMethod â­
- Electronic check âŒ (high churn)
- Automatic payments âœ… (low churn)

## 1ï¸âƒ£9ï¸âƒ£ MonthlyCharges
- Monthly bill amount
- Higher charges â†’ dissatisfaction

## 2ï¸âƒ£0ï¸âƒ£ TotalCharges
- Total amount paid
- Correlated with tenure & monthly charges

## 2ï¸âƒ£1ï¸âƒ£ Churn (TARGET)
- Yes / No
- What we predict


## ğŸ› ï¸ Project Workflow (Steps Done)

- Data Loading & Exploration
  ```python
  Imported required libraries
  Loaded dataset
  Checked shape and data info
  Identified data types & missing values

- Data Cleaning
  ```python
  Converted TotalCharges from object â†’ numeric
  Replaced missing values with median
  Removed CustomerID

- Exploratory Data Analysis (EDA)

- ğŸ“Œ Overall Churn Rate
   ```python
   No: 73.46%
   Yes: 26.54%
   âš ï¸ Dataset is imbalanced

- ğŸ“Œ Churn vs Contract
  
  | Contract       | Churn Rate  |
  | -------------- | ----------- |
  | Month-to-month | **42.7% âŒ** |
  | One year       | 11.3%       |
  | Two year       | **2.8% âœ…**  |

  â¡ï¸ Contract type is a critical churn driver

- ğŸ“Œ Churn vs Tenure

  | Churn | Mean Tenure |
  | ----- | ----------- |
  | No    | ~38 months  |
  | Yes   | ~18 months  |

  â¡ï¸ New customers churn more

- ğŸ“Œ Churn vs Payment Method

   | Payment Method       | Churn Rate  |
   | -------------------- | ----------- |
   | Electronic check     | **45.3% âŒ** |
   | Mailed check         | 19.1%       |
   | Bank transfer (auto) | 16.7%       |
   | Credit card (auto)   | **15.2% âœ…** |

   â¡ï¸ Automatic payments improve retention

- ğŸ“Œ Churn vs Internet Service

   | Internet Service | Churn Rate  |
   | ---------------- | ----------- |
   | Fiber optic      | **41.9% âŒ** |
   | DSL              | 18.9%       |
   | No internet      | **7.4% âœ…**  |

   â¡ï¸ Premium service â‰  lower churn

- ğŸ”¥ High-Risk Customer Profile
  ```python
  Month-to-month contract
  Short tenure
  Electronic check
  Fiber optic

- Data Preprocessing
  ```python
  Label Encoding for categorical features
  Train-test split
  Feature scaling using StandardScaler

- Model Training
  ```python
  RandomForestClassifier
  class_weight = 'balanced'

- Model Evaluation (Before SMOTE)
  ```python
  Class 1 (Churn):
  Precision = 0.61
  Recall    = 0.46
  F1-score  = 0.53
  Accuracy  = 0.78

  âš ï¸ Issues:
  Imbalanced data
  Model biased toward non-churn
  Misses many churners

  âŒ Business Impact:
  Customers leave without intervention
  Revenue loss

- Apply SMOTE (Oversampling)
  ```python
  Balanced minority class
  Retrained model

- Model Evaluation (After SMOTE)
  ```python
   Class 1 (Churn):
   Precision = 0.55
   Recall    = 0.58
   F1-score  = 0.56
   Accuracy  = 0.77

   SMOTE now provides artificial churn examples.
   The model now sees churn patterns more clearly.
   It is now bolder in predicting churn.

   Key changes:
   Recall â†‘ from 0.46 â†’ 0.58
   F1-score â†‘ from 0.53 â†’ 0.56
   Precision â†“ slightly (expected)

## ğŸ“Š Before vs After Comparison

| Metric            | Before | After    | Interpretation       |
| ----------------- | ------ | -------- | -------------------- |
| Recall (Churn)    | 0.46   | **0.58** | Capture more churn âœ… |
| Precision (Churn) | 0.61   | 0.55     | More false alarms âš ï¸ |
| F1-score          | 0.53   | **0.56** | Better balance âœ…     |
| Accuracy          | 0.78   | 0.77     | Not important        |

## ğŸ† Final Conclusion

Applying SMOTE significantly improved the modelâ€™s ability to detect churners by increasing recall and F1-score, which is more aligned with real business objectives where missing a churner is more costly than false alarms.

## ğŸ’¾ Deployment Preparation
- Saved trained model
- Saved scaler for future inference & deployment

## ğŸš€ Future Improvements
- ROC & PR curves
- Threshold tuning
- SHAP feature importance
- Trying other models like XGBoost / LightGBM 
